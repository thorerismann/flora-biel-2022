{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9893caa-0e8b-4989-a504-9efd9b456d29",
   "metadata": {},
   "source": [
    "This notebook pretreats the following data for use in analysis:\n",
    "* survey data collected using the infoflora application.\n",
    "* survey data collected without the infoflora application\n",
    "* The invasives species list, last updated in 2016, available [here](https://www.infoflora.ch/fr/neophytes/neophytes.html)\n",
    "* The redlist of endangered species, updated in 2019, avaialble __.\n",
    "* The list of priority species, updated in ___, available __.\n",
    "* The welten sutter lists in and around Biel/Bienne\n",
    "* 20 square kilomters of 5x5 observations centered on Bienne from Infoflora available __\n",
    "\n",
    "Unneeded columns are dropped, names are homogenized and dictionary keys/codes are created for the different classifications.\n",
    "* removing extraneous data (mainly columns, some rows)\n",
    "* linking some other useful information to the data (species conservation status, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb555be-877f-4494-87fb-18a75bde319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "# math and data packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# charting and graphics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import colors\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# os and file types\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3950c82-bd42-4510-8a29-e9b54a68ed2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlrd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# invasive preprocess\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# main work is to combine the columns containing the geographic distribution, the threats posed, and the habitats for the invasive species.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# note that no reference number is provided by infoflora with this data set, unlike the others.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# load the invasive species data from infoflora\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m invasive \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/BL_WL_2014_f_v2020_05_18.xls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# drop 4 empty rows of nan values at the end of the data set\u001b[39;00m\n\u001b[0;32m     10\u001b[0m invasive\u001b[38;5;241m=\u001b[39m invasive\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py:24\u001b[0m, in \u001b[0;36mXlrdReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mReader using xlrd engine.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall xlrd >= 1.0.0 for Excel support\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mxlrd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr_msg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo-env\\lib\\site-packages\\pandas\\compat\\_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "# invasive preprocess\n",
    "\n",
    "# main work is to combine the columns containing the geographic distribution, the threats posed, and the habitats for the invasive species.\n",
    "# note that no reference number is provided by infoflora with this data set, unlike the others.\n",
    "\n",
    "# load the invasive species data from infoflora\n",
    "invasive = pd.read_excel(\"data/BL_WL_2014_f_v2020_05_18.xls\", header = 2)\n",
    "\n",
    "# drop 4 empty rows of nan values at the end of the data set\n",
    "invasive= invasive.iloc[:-4]\n",
    "\n",
    "# turn threat columns in invasive db into more useable framework. The resulting column is a list containing the threats specified in mythreats.\n",
    "# note result are strings of integers, not integers!\n",
    "\n",
    "mythreats = [\"Potentiel d'expansion\",'écologie, biodiversité']\n",
    "\n",
    "mylist = []\n",
    "\n",
    "for i in invasive.index:\n",
    "    mysublist = []\n",
    "    for j in mythreats:\n",
    "        if not pd.isna(invasive.loc[i,j]):\n",
    "            mysublist.append([j,invasive.at[i,j]])\n",
    "    mylist.append(mysublist)\n",
    "    for k in mylist:\n",
    "        for l in k:\n",
    "            if \"xxx\" in l[1]:\n",
    "                l[1] = \"3\"\n",
    "            if \"xx\" in l[1]:\n",
    "                l[1] = \"2\"\n",
    "            if \"x\" in l[1]:\n",
    "                l[1] = \"1\"\n",
    "            if \"o\" in l[1]:\n",
    "                l[1] = '0'\n",
    "invasive[\"threats\"] = mylist\n",
    "\n",
    "# turn location of invasives columns from db into more useable framework. The resulting column is a list containing the status of the places specified in myplaces.\n",
    "# note result are strings of integers, not integers!\n",
    "\n",
    "myplaces = ['Jura', 'Plateau','non établi en Suisse']\n",
    "\n",
    "mylist = []\n",
    "\n",
    "for i in invasive.index:\n",
    "    mysublist = []\n",
    "    for j in myplaces:\n",
    "        if not pd.isna(invasive.loc[i,j]):\n",
    "            mysublist.append([j,invasive.at[i,j]])\n",
    "    mylist.append(mysublist)\n",
    "    for k in mylist:\n",
    "        for l in k:\n",
    "            if \"xxx\" in l[1]:\n",
    "                l[1] = \"3\"\n",
    "            if \"xx\" in l[1]:\n",
    "                l[1] = \"2\"\n",
    "            if \"x\" in l[1]:\n",
    "                l[1] = \"1\"\n",
    "            if \"o\" in l[1]:\n",
    "                l[1] = '0'\n",
    "invasive[\"places\"] = mylist\n",
    "\n",
    "# collect all of the habitat data into one column. \n",
    "#In the db the presence of a species in each habitat is provided as a checkmark in the relevant column.\n",
    "# For each species in the db, this code makes a list of the column names with a checkmark, and stores this data under a new \"habitat\" column\n",
    "\n",
    "myhabitats = ['1 Eaux libres', '2 Rivages et lieu humides',\n",
    "          '3 Glaciers, rochers, éboulis et moraines', '4 Pelouses et prairies',\n",
    "          '5 Landes, lisières et mégaphorbiaies', '6 Forêts',\n",
    "          '7 Végétations pionnières des endroits perturbés',\n",
    "          '8 Plantations, champs, cultures', '9 Milieux construits']\n",
    "mylist = []\n",
    "for i in invasive.index:\n",
    "    mysublist = []\n",
    "    for j in myhabitats:\n",
    "        if not pd.isna(invasive.loc[i,j]):\n",
    "            mysublist.append(j)\n",
    "    mylist.append(mysublist)\n",
    "invasive[\"habitat\"] = mylist\n",
    "\n",
    "# keep select columns and write result to csv\n",
    "keep_invasives = ['Latein','Black List / Watch List 2014','Ordonnonce sur la dissémination des organismes (ODE)', 'threats','places', 'habitat']\n",
    "inv = invasive[keep_invasives].copy()\n",
    "inv.to_csv(\"output/invasive_preproc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c62929-5554-48a4-b5af-302fcfe2ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redlist preprocess\n",
    "redlist = pd.read_excel(\"data/CH-RLreg_Tracheophyta_2019.xlsx\", engine = 'openpyxl',header = 1)\n",
    "\n",
    "#turn the redlist criteria for each region into a function of the first letter which denotes the general reason behind its classification.\n",
    "#at this stage, no need for the rest of the details\n",
    "mycriteria = ['crit_CH','crit_JU','crit_MP']\n",
    "mylist = []\n",
    "\n",
    "for i in redlist.index:\n",
    "    for j in mycriteria:\n",
    "        if not pd.isna(redlist.loc[i,j]):\n",
    "            split = redlist.at[i,j].split(\";\")\n",
    "            split[0] = split[0][0]\n",
    "            if len(split) > 1:\n",
    "                if (split[1][0] == \" \")|(split[1][0] == \"\\t\"):\n",
    "                    split[1] = split[1][1:]\n",
    "                split[1] = split[1][0]\n",
    "            redlist.at[i,j] = split\n",
    "\n",
    "# drop columns not relevant, write to new csv file\n",
    "keep_redlist = ['ID_ISFS','FAMILY','GENUS','Scientific name','CH','crit_CH', 'JU', 'crit_JU', 'MP', 'crit_MP']\n",
    "red = redlist[keep_redlist].copy()\n",
    "red.to_csv(\"output/redlist_preproc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab4bf2-0284-4d73-9863-086d763ec76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data, comes in batches of 4000 observations\n",
    "\n",
    "first = pd.read_csv(\"data/obs_export_2022-05-08_23h20.csv\",encoding = \"utf-16\",sep = \"\\t\")\n",
    "second = pd.read_csv(\"data/obs_export_2022-05-08_23h21.csv\",encoding = \"utf-16\",sep = \"\\t\")\n",
    "\n",
    "#concatonate the different datasets of observations\n",
    "\n",
    "all_data = pd.concat([first,second],ignore_index = True)\n",
    "\n",
    "# check data / column names\n",
    "\n",
    "#for i in all_data.columns:\n",
    "#    print(F\"column {i} ++ value {all_data.at[0,i]}\")\n",
    "#all_data.columns\n",
    "\n",
    "# test for NAN values\n",
    "\n",
    "#a = all_data.altitude_min.isna()\n",
    "#for i in a:\n",
    "#    if i:\n",
    "#        print('an NA')\n",
    "#    else:\n",
    "#        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229da97-806b-4d3f-9e6a-65f2515bdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys for interpreting redlist data\n",
    "redlist_key_places = {'JU':'Jura','MP':'Middle Plateau'}\n",
    "redlist_key_status = {'EN':'Endangered', 'VU': 'Vulnerable','RE':'Extinct','CR': 'Critically Edangered',\n",
    "                     'NT': 'Near Threatened','LC':'Least Concern','DD':'Data deficient',\n",
    "                      'NA':'Not Applicable','NE': 'Not Evaluated'}\n",
    "redlist_key_criteria = {'A': 'decrease in population size','B':'Habitat fragmentation',\n",
    "                        'C':'initial small population, decrease','D':'very small habitat/population size'}\n",
    "\n",
    "\n",
    "\n",
    "# key to interpret infoflora survey data\n",
    "\n",
    "# key to interpret priority data, to finish\n",
    "priority_canton_key = {'JU':'Jura','BE':'Bern'}\n",
    "# priority_laws_key = {'Espèce cible forestière':'','Espèce agricole OEA','Espèce endémique','Espèce Émeraude':'Bern convention','Espèce protégée':'Protected under art. 20'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e19435-e188-4b5c-b1bb-29490a315980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priority species \n",
    "priority = pd.read_excel('data/ch_priority_species.xlsx',header = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c96a3-9e13-4600-9f37-1f993d71ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate habitat data\n",
    "\n",
    "myhabitats = list(range(1,10))\n",
    "mylist = []\n",
    "\n",
    "for i in priority.index:\n",
    "    mysublist = []\n",
    "    for j in myhabitats:\n",
    "        if priority.loc[i,j] == 'x':\n",
    "            mysublist.append(j)\n",
    "    mylist.append(mysublist)\n",
    "priority[\"habitat\"] = mylist\n",
    "\n",
    "# consolidate provided legal status data\n",
    "\n",
    "mylaws = ['Waldzielart','Landwirtschaftl. UZL-Art','Endemische Art','Smaragd- Art','Geschützte Art NHV']\n",
    "\n",
    "mylist = []\n",
    "\n",
    "for i in priority.index:\n",
    "    mysublist = []\n",
    "    for j in mylaws:\n",
    "        if not pd.isna(priority.loc[i,j]):\n",
    "            mysublist.append(j)\n",
    "    mylist.append(mysublist)\n",
    "priority[\"protection\"] = mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72056e3a-259f-443e-807f-e84c01c5eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_priority = ['Taxon ID','Taxon ID InfoSpecies','Taxon Name','Habitatkombination','Jura','Mittelland','habitat','Kollin','Montan','JU','BE','Priorität','Verantwortung','protection']\n",
    "pri = priority[keep_priority].copy()\n",
    "pri.to_csv(\"output/priority_preproc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bccf2b-d02e-422b-8098-e953d3e6da1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9101e-bf34-419f-94c9-2c22475fe779",
   "metadata": {},
   "source": [
    "Next, the irrelevant columns are removed. InfoFlora provides documentation on the column names available [here](https://www.infoflora.ch/fr/assets/content/documents/Demande_donnees/legende_fr.pdf). The following is the list of columns downloaded: \n",
    "       \n",
    "       'obs_id', 'releve_id', 'project.id', 'project.copyright',\n",
    "       'project.project_name', 'releve_type', 'date', 'date_precision',\n",
    "       'date_expert', 'v_accepted_taxon_id', 'taxon.taxon_id',\n",
    "       'taxon.taxon_name', 'taxon.no_isfs', 'taxon_orig', 'taxon_expert',\n",
    "       'determinavit_cf', 'determinavit', 'introduced', 'introduced_expert',\n",
    "       'municipality.id', 'municipality.name', 'municipality_expert',\n",
    "       'locality_descript', 'srid', 'x', 'y', 'geometry', 'xy_type',\n",
    "       'xy_precision', 'geo_expert', 'altitude_min', 'altitude_max',\n",
    "       'altitude_expert', 'specimen_type', 'presence', 'count_unit',\n",
    "       'abundance_code', 'cover', 'habitat.typo_ch_id', 'habitat.name',\n",
    "       'phenology', 'vitality', 'rem', 'v_validation_status', 'v_observers',\n",
    "       'v_co_canton', 'documents', 'supplements.obs_type',\n",
    "       'supplements.project_obs_id', 'supplements.abundance',\n",
    "       'supplements.pop_length', 'supplements.pop_width',\n",
    "       'supplements.plant_height', 'supplements.depth_min',\n",
    "       'supplements.depth_max', 'supplements.sexe',\n",
    "       'supplements.releve_stratum', 'supplements.cover_abs',\n",
    "       'supplements.cat_aggregation', 'supplements.substrate',\n",
    "       'last_modified_when',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d998f-f2d2-4027-8ad0-fbb8d119a93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = {'obs_id':'unique identifier','date':'date of survey','x':'coordinate gis', 'y':'coordinate gis', 'taxon.taxon_id':'unique species identifier for infoflora reference',\n",
    "            'taxon.no_isfs': 'unique species identifier for infoflora reference','taxon_orig':'original species name selected','municipality.name' : 'name of municipality sample taken',\n",
    "            'phenology' : 'stage of growth','locality_descript' : 'name of survey site','specimen_type' : 'if there is a photo','v_co_canton' : 'name of canton sample taken',\n",
    "            'xy_precision' : 'accuracy of x,y coordinates','altitude_min' : 'altitude for observations','cover':'coverage of area with the species'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2580d-9771-45d5-97cf-e6891fb932fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info_cols.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03b8f7-ac94-4f9e-b60e-9c15fa81feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the columns to keep out of the entire set of data.\n",
    "columns_keep = ['obs_id', 'date','determinavit_cf', 'taxon.taxon_id', 'taxon_orig','municipality.id','municipality.name', 'x', 'y', 'phenology','cover','altitude_min','locality_descript','specimen_type', 'v_co_canton','xy_precision']\n",
    "columns_try = info_cols.keys()\n",
    "# make a new df out of those columns\n",
    "ad = all_data[columns_try].copy()\n",
    "ad.to_csv(\"output/alldata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bb0a3-58d6-4a9a-88f3-b935cc79022c",
   "metadata": {},
   "source": [
    "Initial data work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b16992-623b-429e-938e-724657ce8671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83ad672-7ef7-4e3b-ad22-76304e65ed6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
